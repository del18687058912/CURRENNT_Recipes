random_seed          = 1811626773
max_epochs_no_best   = 6
max_epochs           = 80
learning_rate        = 8e-05
network              = ./network.jsn
train                = true

train_file           = /work/smg/wang/PROJ/F0MODEL/DATA/F009/DATA_TRAIN/data.nc1,/work/smg/wang/PROJ/F0MODEL/DATA/F009/DATA_TRAIN/data.nc2,/work/smg/wang/PROJ/F0MODEL/DATA/F009/DATA_TRAIN/data.nc3,/work/smg/wang/PROJ/F0MODEL/DATA/F009/DATA_TRAIN/data.nc4,/work/smg/wang/PROJ/F0MODEL/DATA/F009/DATA_TRAIN/data.nc5,/work/smg/wang/PROJ/F0MODEL/DATA/F009/DATA_TRAIN/data.nc6,/work/smg/wang/PROJ/F0MODEL/DATA/F009/DATA_TRAIN/data.nc7,/work/smg/wang/PROJ/F0MODEL/DATA/F009/DATA_TRAIN/data.nc8,/work/smg/wang/PROJ/F0MODEL/DATA/F009/DATA_TRAIN/data.nc9,/work/smg/wang/PROJ/F0MODEL/DATA/F009/DATA_TRAIN/data.nc10
val_file             = /work/smg/wang/PROJ/F0MODEL/DATA/F009/DATA_VAL/data.nc1

cache_path           = /tmp/xwtemp

weights_dist         = uninorm
weights_normal_sigma = 0.1
weights_normal_mean  = 0
stochastic           = true
validate_every       = 1
parallel_sequences   = 10
input_noise_sigma    = 0
shuffle_fractions    = false
shuffle_sequences    = false

momentum	     = 0
autosave 	     = true

# Optimizer: SGD gradually decays
Optimizer            = 4

# Configuration for MDN, here it is a softmax MDN layer
mdn_config           = ./mdn.config

# Training configuration
#  use data dropout
ScheduleSampOpt      = 2
#  dropout rate = 50/100 =0.5
ScheduleSampPara     = 50