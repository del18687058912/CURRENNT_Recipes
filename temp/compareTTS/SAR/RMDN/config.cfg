random_seed          = 3839368179
max_epochs_no_best   = 5
max_epochs           = 50
train                = true
network		     = ./network.jsn

train_file           = /work/smg/wang/PROJ/WE/DNNAM/DATA/F009/DATA_TRAIN/data.nc1,/work/smg/wang/PROJ/WE/DNNAM/DATA/F009/DATA_TRAIN/data.nc2,/work/smg/wang/PROJ/WE/DNNAM/DATA/F009/DATA_TRAIN/data.nc3,/work/smg/wang/PROJ/WE/DNNAM/DATA/F009/DATA_TRAIN/data.nc4,/work/smg/wang/PROJ/WE/DNNAM/DATA/F009/DATA_TRAIN/data.nc5,/work/smg/wang/PROJ/WE/DNNAM/DATA/F009/DATA_TRAIN/data.nc6,/work/smg/wang/PROJ/WE/DNNAM/DATA/F009/DATA_TRAIN/data.nc7,/work/smg/wang/PROJ/WE/DNNAM/DATA/F009/DATA_TRAIN/data.nc8,/work/smg/wang/PROJ/WE/DNNAM/DATA/F009/DATA_TRAIN/data.nc9,/work/smg/wang/PROJ/WE/DNNAM/DATA/F009/DATA_TRAIN/data.nc10,/work/smg/wang/PROJ/WE/DNNAM/DATA/F009/DATA_TRAIN/data.nc11,/work/smg/wang/PROJ/WE/DNNAM/DATA/F009/DATA_TRAIN/data.nc12,/work/smg/wang/PROJ/WE/DNNAM/DATA/F009/DATA_TRAIN/data.nc13,/work/smg/wang/PROJ/WE/DNNAM/DATA/F009/DATA_TRAIN/data.nc14,/work/smg/wang/PROJ/WE/DNNAM/DATA/F009/DATA_TRAIN/data.nc15
val_file             = /work/smg/wang/PROJ/WE/DNNAM/DATA/F009/DATA_VAL/data.nc1
validate_every       = 1
cache_path           = /tmp/xwtemp

autosave 	     = true

weights_dist         = uninorm
weights_normal_sigma = 0.1
weights_normal_mean  = 0

stochastic           = true

input_noise_sigma    = 0.0
shuffle_fractions    = true
shuffle_sequences    = false
parallel_sequences   = 15

momentum	     = 0


# Optimizer
#  use SGD + AdaGrad
Optimizer            = 3
#  learning rate for SGD
learning_rate        = 4e-06
#  learning rate for AdaGrad
OptimizerSecondLR    = 0.001

# Configuration for RMDN
#  mdn.config is a binary data configuration file. It contains a few numbers:
#  5   # how many distributions assumed ? 5 here
#
#  0   # the start dimension for the distribution's parameter in the output of last hidden layer
#  3   # the end dimension for the distribution's parameter in the output of last hidden layer
#  0   # the start dimension of the feature to be described by the first distribution
#  1   # the end dimension of the feature to be described by the first distribution
#  1   # 1: GMM with a single mixture component, i.e., Gaussian
#      # here, I use a Gaussian distribution to fit the first dimension of the MGC
#      # this Gaussian has three parameters, mixture weight (which is 1), mean, std
#      
#  3   # the start dimension for the distribution's parameter in the output of last hidden layer
#  362 # the end dimension for the distribution's parameter in the output of last hidden layer
#  1   # the start dimension of the feature to be described by the second distribution
#  180 # the end dimension of the feature to be described by the second distribution
#  1   # 1: GMM with a single mixture component, i.e., Gaussian
#      # here, I use another Gaussian to fit all the rest MGC features
#
#  ... # the rest configuraiton is similar to those above
#      # Please check createMDNConfig.py to know how it was created
mdn_config           = ./mdn.config
#  don't tie the variance matrix of GMM
tieVariance          = 0

# Initialization
#  use the pre-trained RNN to initialize RMDN
trainedModel         = ../../RNN/001/trained_network.jsn 
#  initialize all the layers except the input, last hidden, and MDN layers
trainedModelCtr      = 0111100
#  parameter to initialize the last hidden layer's weight
#  these parameters work differently for different types of distribution in MDN layer
#  please search MDNUnit_mixture<TDevice>::initPreOutput in CURRENNT/currennt_lib/src/layers/MDNUnit.cu
#  for more information
wInitPara            = 20
varInitPara          = 0.001
